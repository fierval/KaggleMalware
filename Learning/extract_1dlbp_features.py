from numba import *
from numbapro import cuda
from timeit import default_timer as timer

import numpy as np
import os
from os import path
import shutil
from tr_utils import append_to_arr, prep_out_path
from train_files import TrainFiles

inp_path = "/kaggle/malware/scrapbook"
out_path = path.join(inp_path, "1dlbp")
ext = ".lbp"

neighborhood = 4

@cuda.jit('void(uint8[:], int32, int32[:], int32[:], int32[:])')
def lbp_kernel(input, neighborhood, res, powers, h):
    i = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x
    if i < res.shape[0]:
        i += neighborhood
        for j in range(i - neighborhood, i):
            if input[j] >= input[i]:
                res [i - neighborhood] += powers[j - i + neighborhood]
    
        for j in range(i + 1, i + neighborhood + 1):
            if input[j] >= input[i]:
                res [i - neighborhood] += powers[j - i + neighborhood - 1]

    cuda.syncthreads()
    if i < res.shape[0]:
        cuda.atomic.add(h, res [i - neighborhood], 1)

def extract_1dlbp_gpu_debug(input, neighborhood):
    res = np.zeros((input.shape[0] - 2 * neighborhood), dtype='int32')
    powers = 2 ** np.array(range(0, 2 * neighborhood), dtype='int32')

    maxThread = 512
    blockDim = maxThread
    gridDim = (len(input) - 2 * neighborhood + blockDim) / blockDim
    
    for block in range(0, gridDim):
        for thread in range(0, blockDim):
            i = blockDim * block + thread
            if i >= res.shape[0]:
                return res

            i += neighborhood
            for j in range(i - neighborhood, i):
                if input[j] >= input[i]:
                    res [i - neighborhood] += powers[neighborhood - (i - j)]
    
            for j in range(i + 1, i + neighborhood + 1):
                if input[j] >= input[i]:
                    res [i - neighborhood] += powers[j - i + neighborhood - 1]
    return res

def extract_1dlbp_gpu(input, neighborhood, d_powers):
    maxThread = 512

    blockDim = maxThread
    gridDim = (len(input) - 2 * neighborhood + blockDim) / blockDim
    d_input = cuda.to_device(input)

    res = np.zeros((input.shape[0] - 2 * neighborhood), dtype='int32')
    hist = np.zeros(2 ** (2 * neighborhood), dtype='int32')

    d_res = cuda.to_device(res)
    d_hist = cuda.to_device(hist)

    lbp_kernel[gridDim, blockDim](d_input, neighborhood, d_res, d_powers, d_hist)
    d_hist.to_host()
    return hist

def extract_1dlbp_cpu(input, neighborhood, p):
    """
    Extract the 1d lbp pattern on CPU
    """
    res = np.zeros((input.shape[0] - 2 * neighborhood))
    for i in range(neighborhood, len(input) - neighborhood):
        smaller = input[i - neighborhood : i]
        larger = input[i + 1 : i + neighborhood + 1]
        all = np.r_[smaller, larger]
        res[i - neighborhood] = np.sum(p [all >= input[i]])
    return res

def file_histogram(lbps, neighborhood):
    bins = 2 ** (2 * neighborhood)
    hist = np.zeros(bins, dtype='int')

    for lbp in lbps:
        hist[lbp] += 1

    return hist

def get_1dlbp_features(neighborhood):
    tf = TrainFiles(inp_path, floor = neighborhood * 2 + 1)
    inputs = tf.get_training_inputs()

    start = timer()
    hist = np.array([])
    outs = np.array([])

    i = 0
    writeBatch = 2000
    prep_out_path(out_path)

    p = 1 << np.array(range(0, 2 * neighborhood), dtype='int32')
    d_powers = cuda.to_device(p)

    for inp in inputs:

        data_file = path.join(inp_path, inp)

        out_file = path.join(out_path, path.splitext(inp)[0] + ext)
        arr = np.fromfile(data_file, dtype = 'uint8')

        ##GPU##
        file_hist = extract_1dlbp_gpu(arr, neighborhood, d_powers)

        ##CPU##
        #file_hist = extract_1dlbp_cpu(arr, neighborhood, p)
        #file_hist = file_histogram(file_hist, neighborhood)

        i += 1
        hist = append_to_arr(hist, file_hist)
        outs = append_to_arr(outs, out_file)

        if i == writeBatch:
            i = 0
            first = True
            print "Writing....."
            for j in range(0, outs.shape[0]):
                hist[j].tofile(outs[j])
            hist = np.array([])
            outs = np.array([])



    print "==============Done==================="
    print "Elapsed: ", timer() - start

    print "Writing......."

    for i in range(0, outs.shape[0]):
        hist[i].tofile(outs[i])

    print "==============Done==================="

