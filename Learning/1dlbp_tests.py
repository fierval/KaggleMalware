import numpy as np
import matplotlib.pylab as plt

from numba import cuda, uint8, int32, uint32
from timeit import default_timer as timer

maxThread = 512

@cuda.jit('void(uint8[:], int32, uint8[:], int32[:], int32[:])')
def lbp_kernel(input, neighborhood, res, powers, h):
    i = cuda.grid(1)
    if i < input.shape[0] - 2 * neighborhood:
        i += neighborhood
        for j in range(i - neighborhood, i):
            if input[j] >= input[i]:
                res [i - neighborhood] += powers[j - i + neighborhood]
    
        for j in range(i + 1, i + neighborhood + 1):
            if input[j] >= input[i]:
                res [i - neighborhood] += powers[j - i + neighborhood - 1]

        cuda.atomic.add(h, res[i - neighborhood], 1)

def extract_1dlbp_gpu(input, neighborhood, d_powers):
    blockDim = maxThread
    d_input = cuda.to_device(input)

    hist = np.zeros(2 ** (2 * neighborhood), dtype='int32')
    res = np.zeros(len(input) - 2 * neighborhood, dtype = 'uint8')
    d_res = cuda.to_device(res)
    gridDim = (len(res) + blockDim) / blockDim

    d_hist = cuda.to_device(hist)

    lbp_kernel[gridDim, blockDim](d_input, neighborhood, d_res, d_powers, d_hist)
    d_hist.to_host()
    return hist

def extract_1dlbp_gpu_debug(input, neighborhood):
    res = np.zeros((input.shape[0] - 2 * neighborhood), dtype='int32')
    powers = 2 ** np.array(range(0, 2 * neighborhood), dtype='int32')

    maxThread = 512
    blockDim = maxThread
    gridDim = (len(input) - 2 * neighborhood + blockDim) / blockDim
    
    for block in range(0, gridDim):
        for thread in range(0, blockDim):
            i = blockDim * block + thread
            if i >= res.shape[0]:
                return res

            i += neighborhood
            for j in range(i - neighborhood, i):
                if input[j] >= input[i]:
                    res [i - neighborhood] += powers[j - i + neighborhood]
    
            for j in range(i + 1, i + neighborhood + 1):
                if input[j] >= input[i]:
                    res [i - neighborhood] += powers[j - i + neighborhood - 1]
    return res


def extract_1dlbp_cpu(input, neighborhood, p):
    """
    Extract the 1d lbp pattern on CPU
    """
    res = np.zeros((input.shape[0] - 2 * neighborhood))
    for i in range(neighborhood, len(input) - neighborhood):
        left = input[i - neighborhood : i]
        right = input[i + 1 : i + neighborhood + 1]
        both = np.r_[left, right]
        res[i - neighborhood] = np.sum(p [both >= input[i]])
    return res

def file_histogram(lbps, neighborhood):
    """
    Create a histogram out of the exracted pattern
    """
    bins = 2 ** (2 * neighborhood)
    hist = np.zeros(bins, dtype='int')

    for lbp in lbps:
        hist[lbp] += 1

    return hist

X = np.arange(3, 7)
X = 10 ** X
neighborhood = 4

cpu_times = np.zeros(X.shape[0])
gpu_times = np.zeros(X.shape[0])

p = 1 << np.array(range(0, 2 * neighborhood), dtype='int32')
d_powers = cuda.to_device(p)

for i, x in enumerate(X):
    input = np.random.randint(0, 256, size = x).astype(np.uint8)
    start = timer()
    h_cpu = file_histogram(extract_1dlbp_cpu(input, neighborhood, p), neighborhood)
    cpu_times[i] = timer() - start
    print "Finished on CPU: length: {0}, time: {1:3.4f}s".format(x, cpu_times[i])

    start = timer()
    h_gpu = extract_1dlbp_gpu(input, neighborhood, d_powers)
    gpu_times[i] = timer() - start
    print "Finished on GPU: length: {0}, time: {1:3.4f}s".format(x, gpu_times[i])
    print "All h_cpu == h_gpu: ", (h_cpu == h_gpu).all()

f = plt.figure(figsize=(10, 5))

plt.plot(X, cpu_times, label = "CPU")
plt.plot(X, gpu_times, label = "GPU")
plt.yscale('log')
plt.xscale('log')
plt.xlabel('input length')
plt.ylabel('time, sec')
plt.legend()

