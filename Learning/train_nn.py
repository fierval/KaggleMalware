from pybrain.datasets            import ClassificationDataSet, UnsupervisedDataSet
from pybrain.utilities           import percentError
from pybrain.tools.shortcuts     import buildNetwork

from pybrain.supervised.trainers import BackpropTrainer
from pybrain.unsupervised.trainers.deepbelief import DeepBeliefTrainer
from pybrain.structure.networks import FeedForwardNetwork
from pybrain.structure.modules import SigmoidLayer, SoftmaxLayer

import train_files as utils
import time

import numpy as np

from sklearn.metrics import log_loss
from sklearn.preprocessing import StandardScaler

import matplotlib.pyplot as plt
from pybrain.structure.modules.linearlayer import LinearLayer

from scipy import stats
from pybrain.structure.modules.tanhlayer import TanhLayer
from pybrain.structure.connections.full import FullConnection
from pybrain.structure.modules.biasunit import BiasUnit
from pybrain.unsupervised.trainers.rbm import RbmGibbsTrainerConfig, RbmGibbsTrainer, RbmGaussTrainer
from pybrain.structure.networks.rbm import Rbm

train_path = "/kaggle/malware/scratchpad/train/1dlbp"
test_path = "/kaggle/malware/scratchpad/test/1dlbp"
labels_file = "/kaggle/malware/trainLabels.csv"

def _createDataSet(X, Y, one_based):
    labels = np.unique(Y)
    alldata = ClassificationDataSet(X.shape[1], nb_classes = labels.shape[0], class_labels = labels)
    shift = 1 if one_based else 0
    for i in range(X.shape[0]):
        alldata.addSample(X[i], Y[i] - shift)
    
    alldata._convertToOneOfMany()
    return alldata

def preTrainWithDecForests(X_train, Y_train, X_test, Y_test, importance = 0.0035):
    trees, features = train_utils.train_dec_forest(X_train, Y_train, X_test, Y_test, importance)

    print "Features: ", features.shape

    return X_train[:, features], X_test[:, features]

def createDataSets(X_train, Y_train, X_test, Y_test, one_based = True):
    """
    Creates the data set. Handles one-based classifications (PyBrain uses zero-based ones).
    """
    trndata = _createDataSet(X_train, Y_train, one_based)
    tstdata = _createDataSet(X_test, Y_test, one_based)    
    return trndata, tstdata

def nn_log_loss(fnn, data):
    proba = fnn.activateOnDataset(data)
    return log_loss(data['target'], proba)

def train(trndata, tstdata, epochs = 100, test_error = 0.02, weight_decay = 0.0001, momentum = 0.15):
    """
    FF neural net
    """

    fnn = buildNetwork(trndata.indim, trndata.indim / 4, trndata.outdim, outclass = SoftmaxLayer)

    trainer = BackpropTrainer(fnn, trndata, momentum = momentum, weightdecay = weight_decay)

    epoch_delta = 1
    stop = False
    
    trnResults = np.array([])
    tstResults = np.array([])
    totEpochs = np.array([])

    trnLogLoss = np.array([])
    tstLogLoss = np.array([])

    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,8))
    #hold(True) # overplot on

    #plt.ion()
    while not stop:
        trainer.trainEpochs(epoch_delta)

        trnresult = percentError( trainer.testOnClassData(),
                              trndata['class'] )
        tstresult = percentError( trainer.testOnClassData(
           dataset=tstdata ), tstdata['class'] )

        tstLogLoss = utils.append_to_arr(tstLogLoss, nn_log_loss(fnn, tstdata))
        trnLogLoss = utils.append_to_arr(trnLogLoss, nn_log_loss(fnn, trndata))

        print "epoch: %4d" % trainer.totalepochs, \
          "  train error: %5.2f%%" % trnresult, \
          "  test error: %5.2f%%" % tstresult, \
          " test logloss: %5.2f" % tstLogLoss[-1]
        
        trnResults = utils.append_to_arr(trnResults, trnresult)
        tstResults = utils.append_to_arr(tstResults, tstresult)
        totEpochs = utils.append_to_arr(totEpochs, trainer.totalepochs)
        
        plt.sca(ax1)
        plt.cla()
        ax1.plot(totEpochs, trnResults, label = 'Train')
        ax1.plot(totEpochs, tstResults, label = 'Test')

        plt.sca(ax2)
        plt.cla()
        ax2.plot(totEpochs, trnLogLoss, label = 'Train')
        ax2.plot(totEpochs, tstLogLoss, label = 'Test')

        ax1.legend()
        ax2.legend()

        plt.draw()
        time.sleep(0.1)
        plt.pause(0.0001)

        stop = ((trnresult <= test_error) and (tstresult <= test_error)) or (trainer.totalepochs >= epochs)
    return fnn

def do_train():
    X, Y, Xt, Yt, _ = train_utils.prepare_inputs(train_path, test_path, labels_file, scaling = 'log')
    #X_sel, Xt_sel = preTrainWithDecForests(X, Y, Xt, Yt, importance = 0.0025)

    trndata, tstdata = createDataSets(X, Y, Xt, Yt)
    train(trndata, tstdata, epochs = 1000)
       