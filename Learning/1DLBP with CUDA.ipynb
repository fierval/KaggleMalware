{
 "metadata": {
  "name": "",
  "signature": "sha256:82e12c36f489de9f943992930685780fb24d9f9a788d73580980f453aa5f9150"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extracting a 1D Local Binary Pattern Histogram on NVIDIA GPU with CUDA and Numbapro"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This was done for the Microsoft Malware competition on Kaggle. \n",
      "In this contest, a bunch of malware files needed to be classified in 9 categories. The files were presented in two sets, 10,868 each: \n",
      "- text (disassembly of the malware)\n",
      "- binary (actual binaries minus PE header to render them harmless)\n",
      "\n",
      "I chose the [1DLBP](http://www.thinkmind.org/download.php?articleid=future_computing_2013_1_30_30012) algorithm described in the linked paper to extract (hopefully meaningful) features from each binary file. These features, in combination with some text-based features extracted from the disassemblies, proved to be quite effective in training an accurate classifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Prerequisits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- basic knowledge of CUDA programming (kernels, grid, blocks, threads, etc)\n",
      "- numba "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba import *\n",
      "from timeit import default_timer as timer\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pylab as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Algorithm in Brief\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the paper (above) does a great job explaining the algorithm, I will only describe it very briefly.\n",
      "\n",
      "For every byte (b) in the image, we look at 4 (or any neighborhood) of bytes immediately to the \"left\" and at 4 bytes immediately to the \"right\" of the current byte.\n",
      "\n",
      "We now have 8 selected bytes, call them c[], where size(c) = 8. Each of the elements of array c is converted into a binary digit, based on the following rule:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = np.random.randint(0, 256, size=8) #neighborhood bytes to the left and to the right contain these values\n",
      "b = np.random.randint(256) # center of the neighborhood\n",
      "digits = np.array([0 if d < b else 1 for d in c]) # this is the number that represents the pattern\n",
      "print \"Center: \", b\n",
      "print \"Bytes around it: \", c\n",
      "print \"Pattern: \", digits \n",
      "\n",
      "# In order to compute the actual pattern, we just mulitply each of the digits by a power of two and add them up\n",
      "powers = 1 << np.arange(0, 8)\n",
      "print \"As number base 10: \", np.dot(powers, digits.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Center:  83\n",
        "Bytes around it:  [ 95 168 243  84 218 194  97 144]\n",
        "Pattern:  [1 1 1 1 1 1 1 1]\n",
        "As number base 10:  255\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Which is actually a non-negative integer less than $2^8$.\n",
      "\n",
      "Then a histogram of these values is built. It has the size of 256 ints and in training experiments proves to be much more effective than a simple byte histogram.\n",
      "\n",
      "The functions below translate this description into Python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_1dlbp_cpu(input, neighborhood, p):\n",
      "    \"\"\"\n",
      "    Extract the 1d lbp pattern on CPU\n",
      "    \"\"\"\n",
      "    res = np.zeros((input.shape[0] - 2 * neighborhood))\n",
      "    for i in range(neighborhood, len(input) - neighborhood):\n",
      "        left = input[i - neighborhood : i]\n",
      "        right = input[i + 1 : i + neighborhood + 1]\n",
      "        both = np.r_[left, right]\n",
      "        res[i - neighborhood] = np.sum(p [both >= input[i]])\n",
      "    return res\n",
      "\n",
      "def file_histogram(lbps, neighborhood):\n",
      "    \"\"\"\n",
      "    Create a histogram out of the exracted pattern\n",
      "    \"\"\"\n",
      "    bins = 2 ** (2 * neighborhood)\n",
      "    hist = np.zeros(bins, dtype='int')\n",
      "\n",
      "    for lbp in lbps:\n",
      "        hist[lbp] += 1\n",
      "\n",
      "    return hist\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With numba, this can be expressed on the GPU using CUDA.\n",
      "If you have numbapro, CUDA support can be validated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numbapro\n",
      "numbapro.check_cuda()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "------------------------------libraries detection-------------------------------\n",
        "Finding cublas\n",
        "\tlocated at C:\\Anaconda\\DLLs\\cublas64_60.dll\n",
        "\ttrying to open library...\tok\n",
        "Finding cusparse\n",
        "\tlocated at C:\\Anaconda\\DLLs\\cusparse64_60.dll\n",
        "\ttrying to open library...\tok\n",
        "Finding cufft\n",
        "\tlocated at C:\\Anaconda\\DLLs\\cufft64_60.dll\n",
        "\ttrying to open library...\tok\n",
        "Finding curand\n",
        "\tlocated at C:\\Anaconda\\DLLs\\curand64_60.dll\n",
        "\ttrying to open library...\tok\n",
        "Finding nvvm\n",
        "\tlocated at C:\\Anaconda\\DLLs\\nvvm64_20_0.dll\n",
        "\ttrying to open library...\tok\n",
        "\tfinding libdevice for compute_20...\tok\n",
        "\tfinding libdevice for compute_30...\tok\n",
        "\tfinding libdevice for compute_35...\tok\n",
        "-------------------------------hardware detection-------------------------------\n",
        "Found 1 CUDA devices\n",
        "id 0       GeForce GTX TITAN                              [SUPPORTED]\n",
        "                      compute capability: 3.5\n",
        "                           pci device id: 0\n",
        "                              pci bus id: 2\n",
        "Summary:\n",
        "\t1/1 devices are supported\n",
        "PASSED\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am working with GTX Titan, 14 SMs (14 * 192 = 2688 SPs), 6 Gb RAM. This used to be cool a year and a half ago, but a lot has happened since then."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###The Kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@cuda.jit('void(uint8[:], int32, uint8[:], int32[:], int32[:])')\n",
      "def lbp_kernel(input, neighborhood, res, powers, h):\n",
      "\n",
      "    i = cuda.blockDim.x * cuda.blockIdx.x + cuda.threadIdx.x\n",
      "    if i >= res.shape[0]:\n",
      "        return\n",
      "\n",
      "    i += neighborhood\n",
      "    for j in range(i - neighborhood, i):\n",
      "        if input[j] >= input[i]:\n",
      "            res [i - neighborhood] += powers[j - i + neighborhood]\n",
      "    \n",
      "    for j in range(i + 1, i + neighborhood + 1):\n",
      "        if input[j] >= input[i]:\n",
      "            res [i - neighborhood] += powers[j - i + neighborhood - 1]\n",
      "    \n",
      "    cuda.atomic.add(h, res[i - neighborhood], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This looks like a regular CUDA kernel. It almost looksy \"C++y\". Each thread is tasked with computing the pattern (\"digits\" above) around one single element of the original input array. We compute the pattern, then wait for all of the threads in the block to finish and update the histogram with their results. A couple of notes:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- implementation of histogramming using atomics is the most straightforward, but not the most efficient one. For our purposes it will do just fine.\n",
      "- an obvious optimization is to put _res_ into shared memory. This would, however slightly complicate indexing arithmetic, so since the kernel is fast anyway, I'm opting for less code complexity vs a slight increase in performance\n",
      "\n",
      "###Calling the Kernel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_1dlbp_gpu(input, neighborhood, d_powers):\n",
      "    '''\n",
      "    input - the input array\n",
      "    neighborhood - size of the neighborhood \n",
      "    d_powers - device address of the powers of two constants used to compute the final pattern\n",
      "    '''\n",
      "    maxThread = 512\n",
      "\n",
      "    blockDim = maxThread\n",
      "    gridDim = (len(input) - 2 * neighborhood + blockDim) / blockDim\n",
      "    d_input = cuda.to_device(input)\n",
      "\n",
      "    res = np.zeros((input.shape[0] - 2 * neighborhood), dtype='int32')\n",
      "    hist = np.zeros(2 ** (2 * neighborhood), dtype='int32')\n",
      "\n",
      "    d_res = cuda.to_device(res)\n",
      "    d_hist = cuda.to_device(hist)\n",
      "\n",
      "    lbp_kernel[gridDim, blockDim](d_input, neighborhood, d_res, d_powers, d_hist)\n",
      "    d_hist.to_host()\n",
      "    return hist\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Testing"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}